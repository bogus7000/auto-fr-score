{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "# Set the API key\n",
    "open_ai_api_key = 'YOUR_API_KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "scores_data = pd.read_json('../../data/headphones-data.json')\n",
    "scores_data.replace(r'^\\s*$', np.nan, regex=True, inplace=True)\n",
    "scores_data = scores_data.dropna()\n",
    "scores_data = scores_data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def generate_prompt_for_aspect(headphone_data, dataset, aspect):\n",
    "    dataset_filtered = dataset[dataset['id'] != headphone_data['id']]\n",
    "    \n",
    "    score_columns = [f'{aspect}AccuracyScore']\n",
    "    distances = dataset_filtered[score_columns].apply(\n",
    "        lambda row: np.linalg.norm(row - headphone_data[score_columns]), axis=1\n",
    "    )\n",
    "    \n",
    "    closest_indices = distances.nsmallest(10).index\n",
    "    \n",
    "    prompt = \"[CONTEXT]\\n\"\n",
    "    \n",
    "    for idx in closest_indices:\n",
    "        headphone = dataset_filtered.loc[idx]\n",
    "        prompt += f\"- Headphone: {headphone['fullname']}\\n\"\n",
    "        prompt += f\"  - {aspect.capitalize()} accuracy: {headphone[f'{aspect}AccuracyScore']}\\n\"\n",
    "        prompt += f\"  - {aspect.capitalize()} accuracy description: {headphone[f'{aspect}AccuracyDescription']}\\n\"\n",
    "        prompt += \"\\n\"\n",
    "\n",
    "    prompt += \"[TASK]\\nGenerate a description of {} performance score for the following headphone based on this data:\\n\\n\".format(aspect)\n",
    "    prompt += f\"- Headphone: {headphone_data['fullname']}\\n\"\n",
    "    prompt += f\"  - {aspect.capitalize()} accuracy: {headphone_data[f'{aspect}AccuracyScore']}\\n\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def call_gpt4(prompt, client, system_content):\n",
    "    completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_content },\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    )\n",
    "    response = completion.choices[0].message.content\n",
    "    return response.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate descriptions\n",
    "client = OpenAI(api_key=open_ai_api_key)\n",
    "\n",
    "example_headphone_data = scores_data[scores_data['id'] == 325].iloc[0]\n",
    "\n",
    "system_content = \"You are a headphone reviewer. Your descriptions of sound performance scores are short, concise and colorful. You write like your reviewer colleagues, whose writing is provided as reference in the [CONTEXT] section of the prompts that you receive. You do not mention the exact value of the accuracy score that you are describing\"\n",
    "\n",
    "bass_prompt = generate_prompt_for_aspect(example_headphone_data, scores_data, 'bass')\n",
    "print(bass_prompt)\n",
    "bass_description = call_gpt4(bass_prompt, client, system_content)\n",
    "\n",
    "mid_prompt = generate_prompt_for_aspect(example_headphone_data, scores_data, 'mid')\n",
    "mid_description = call_gpt4(mid_prompt, client, system_content)\n",
    "\n",
    "treble_prompt = generate_prompt_for_aspect(example_headphone_data, scores_data, 'treble')\n",
    "treble_description = call_gpt4(treble_prompt, client, system_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare generated and real descriptions\n",
    "real_bass_description = example_headphone_data['bassAccuracyDescription']\n",
    "real_mid_description = example_headphone_data['midAccuracyDescription']\n",
    "real_treble_description = example_headphone_data['trebleAccuracyDescription']\n",
    "\n",
    "data = {\n",
    "    'Aspect': ['Bass', 'Mid', 'Treble'],\n",
    "    'Real Description': [real_bass_description, real_mid_description, real_treble_description],\n",
    "    'Generated Description': [bass_description, mid_description, treble_description]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "fig = go.Figure(data=[go.Table(\n",
    "    header=dict(values=list(df.columns),\n",
    "                fill_color='paleturquoise',\n",
    "                align='left'),\n",
    "    cells=dict(values=[df['Aspect'], df['Real Description'], df['Generated Description']],\n",
    "               fill_color='lavender',\n",
    "               align='left'))\n",
    "])\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Comparison of Real and Generated Descriptions\",\n",
    "    height=800\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auto-fr-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
